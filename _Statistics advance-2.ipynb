{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256ffdc9",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8761c9",
   "metadata": {},
   "source": [
    "\n",
    "The probability mass function (PMF) and probability density function (PDF) are two functions that are used to describe the probability distribution of a random variable. The PMF is used to describe discrete random variables, while the PDF is used to describe continuous random variables.\n",
    "\n",
    "The PMF is a discrete function that takes on a value of 0 or 1 for each possible value of the random variable. The value of 1 indicates that the random variable can take on that value, while the value of 0 indicates that it cannot. The sum of all the values of the PMF must equal 1.\n",
    "\n",
    "For example, let's say we have a random variable that can take on the values 1, 2, or 3. The PMF for this random variable would be a table that shows the probability of each value occurring. The table might look like this:\n",
    "\n",
    "Value | Probability\n",
    "------- | --------\n",
    "1 | 0.2\n",
    "2 | 0.4\n",
    "3 | 0.4\n",
    "\n",
    "The PDF is a continuous function that takes on a value for every possible value of the random variable. The value of the PDF indicates the probability that the random variable will take on a value within a certain range.\n",
    "\n",
    "For example, let's say we have a random variable that can take on any value between 0 and 1. The PDF for this random variable would be a curve that shows the probability of the random variable taking on any value within the range of 0 and 1. The curve might look like this:\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "x | y\n",
    "------- | --------\n",
    "0 | 0\n",
    "0.1 | 0.1\n",
    "0.2 | 0.2\n",
    "0.3 | 0.3\n",
    "0.4 | 0.4\n",
    "0.5 | 0.5\n",
    "0.6 | 0.6\n",
    "0.7 | 0.7\n",
    "0.8 | 0.8\n",
    "0.9 | 0.9\n",
    "1 | 1\n",
    "The PMF and PDF are both important tools for describing the probability distribution of a random variable. The PMF is used for discrete random variables, while the PDF is used for continuous random variables. Both functions can be used to calculate the probability that the random variable will take on a certain value or range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab66a0",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f299e",
   "metadata": {},
   "source": [
    "\n",
    "The cumulative distribution function (CDF) of a random variable X is the function that gives the probability that X is less than or equal to a certain value. It is denoted by F(x).\n",
    "\n",
    "For example, let's say we have a random variable X that can take on any value between 0 and 1. The CDF of X would be a curve that shows the probability that X is less than or equal to a certain value. The curve might look like this:\n",
    "\n",
    "y = F(x)\n",
    "\n",
    "x | y\n",
    "------- | --------\n",
    "0 | 0\n",
    "0.1 | 0.1\n",
    "0.2 | 0.2\n",
    "0.3 | 0.3\n",
    "0.4 | 0.4\n",
    "0.5 | 0.5\n",
    "0.6 | 0.6\n",
    "0.7 | 0.7\n",
    "0.8 | 0.8\n",
    "0.9 | 0.9\n",
    "1 | 1\n",
    "The CDF can be used to calculate the probability that X will take on a certain value or range of values. For example, the probability that X will be less than or equal to 0.5 is 0.5, and the probability that X will be between 0.5 and 0.7 is 0.2.\n",
    "\n",
    "The CDF is also used to calculate the quantiles of a random variable. The quantiles of a random variable are the values that divide the distribution of the random variable into equal probability intervals. For example, the 25th percentile of a random variable is the value that has a probability of 0.25.\n",
    "\n",
    "The CDF is a useful tool for describing the probability distribution of a random variable. It is easy to understand and interpret, and it can be used to calculate a variety of statistical quantities.\n",
    "\n",
    "Here is an example of how the CDF can be used. Let's say we want to know the probability that a randomly selected person is taller than 6 feet. If we know the CDF of the height distribution, we can easily calculate this probability. The CDF will tell us the probability that a randomly selected person is less than or equal to 6 feet. The probability that a randomly selected person is taller than 6 feet is simply 1 minus the probability that the person is less than or equal to 6 feet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0689c11",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81e677",
   "metadata": {},
   "source": [
    "\n",
    "The normal distribution is a bell-shaped curve that is often used to model the distribution of many different types of data. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "The heights of people\n",
    "The weights of people\n",
    "The scores on a test\n",
    "The amount of time it takes to complete a task\n",
    "The number of errors made in a process\n",
    "The parameters of the normal distribution are the mean and the standard deviation. The mean is the average value of the distribution, and the standard deviation is a measure of how spread out the distribution is. The shape of the normal distribution is determined by the mean and the standard deviation.\n",
    "\n",
    "If the mean is high and the standard deviation is low, the distribution will be narrow and peaked.\n",
    "If the mean is low and the standard deviation is high, the distribution will be wide and flat.\n",
    "If the mean and the standard deviation are equal, the distribution will be a perfect bell curve.\n",
    "The normal distribution is a versatile model that can be used to model a wide variety of data. It is a valuable tool for statisticians and data scientists who need to understand the distribution of their data.\n",
    "\n",
    "Here are some additional details about the parameters of the normal distribution:\n",
    "\n",
    "The mean is the most important parameter of the normal distribution. It determines the center of the distribution.\n",
    "The standard deviation is a measure of how spread out the distribution is. The larger the standard deviation, the more spread out the distribution will be.\n",
    "The shape of the normal distribution is determined by the mean and the standard deviation. If the mean and the standard deviation are equal, the distribution will be a perfect bell curve.\n",
    "The normal distribution is a very common distribution in nature and in many different fields of study. It is often used as a model for the distribution of data because it is relatively easy to understand and analyze. The parameters of the normal distribution, the mean and the standard deviation, can be used to describe the shape of the distribution and to make predictions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a6e9b",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c8502",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most important probability distributions in statistics. It is often used as a model for the distribution of data because it is relatively easy to understand and analyze. The parameters of the normal distribution, the mean and the standard deviation, can be used to describe the shape of the distribution and to make predictions about the data.\n",
    "\n",
    "Here are some of the importance of normal distribution:\n",
    "\n",
    "It is used in many different fields of study, including statistics, physics, chemistry, biology, and economics.\n",
    "It is used to model the distribution of many different types of data, such as heights, weights, test scores, and errors.\n",
    "It is used to calculate probabilities, such as the probability that a randomly selected person is taller than 6 feet.\n",
    "It is used to set confidence intervals, which are used to estimate the true value of a population parameter.\n",
    "Here are some real-life examples of normal distribution:\n",
    "\n",
    "The heights of people are normally distributed. This means that most people are of average height, with a few people who are taller and a few people who are shorter.\n",
    "The weights of people are also normally distributed. This means that most people are of average weight, with a few people who are heavier and a few people who are lighter.\n",
    "The scores on a test are normally distributed. This means that most people will score around the average score, with a few people who score higher and a few people who score lower.\n",
    "The amount of time it takes to complete a task is also normally distributed. This means that most people will take around the average amount of time to complete the task, with a few people who take longer and a few people who take less time.\n",
    "The number of errors made in a process is also normally distributed. This means that most processes will have around the average number of errors, with a few processes that have more errors and a few processes that have fewer errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b2e0d",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43003033",
   "metadata": {},
   "source": [
    "Bernoulli Distribution:\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with only two possible outcomes: success (usually denoted by \"1\") and failure (usually denoted by \"0\"). It is named after the Swiss mathematician Jacob Bernoulli, who introduced it in the late 17th century. The Bernoulli distribution is a special case of the binomial distribution, where the number of trials is fixed at one.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where:\n",
    "\n",
    "X is the random variable representing the outcome (1 for success, 0 for failure).\n",
    "p is the probability of success in a single trial (0 ≤ p ≤ 1).\n",
    "Example of Bernoulli Distribution:\n",
    "\n",
    "Consider the random experiment of flipping a fair coin. We can model this situation with a Bernoulli distribution, where success (X = 1) represents getting a \"heads\" and failure (X = 0) represents getting a \"tails.\" Since the coin is fair, the probability of success (getting heads) in a single flip is p = 0.5.\n",
    "\n",
    "The Bernoulli distribution for this coin flip experiment would be:\n",
    "\n",
    "P(X = 1) = 0.5 (probability of getting heads)\n",
    "P(X = 0) = 1 - 0.5 = 0.5 (probability of getting tails)\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "Number of Trials:\n",
    "Bernoulli Distribution: Represents a single trial or a random experiment with only two possible outcomes (success or failure).\n",
    "Binomial Distribution: Represents the number of successes in a fixed number of independent and identical Bernoulli trials.\n",
    "Parameters:\n",
    "Bernoulli Distribution: Has only one parameter, p, which is the probability of success in a single trial.\n",
    "Binomial Distribution: Has two parameters, n and p, where n is the number of trials and p is the probability of success in each trial.\n",
    "Random Variable:\n",
    "Bernoulli Distribution: The random variable X takes only two possible values: 1 (success) and 0 (failure).\n",
    "Binomial Distribution: The random variable Y represents the number of successes in n trials and can take integer values from 0 to n.\n",
    "Probability Mass Function (PMF):\n",
    "Bernoulli Distribution: The PMF of the Bernoulli distribution is given by P(X = x) = p^x * (1 - p)^(1 - x).\n",
    "Binomial Distribution: The PMF of the binomial distribution is given by P(Y = k) = C(n, k) * p^k * (1 - p)^(n - k), where C(n, k) represents the binomial coefficient (number of ways to choose k successes out of n trials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41509e8b",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95973026",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation from the dataset is greater than 60, we need to use the properties of the normal distribution and the z-score formula.\n",
    "\n",
    "The z-score measures how many standard deviations an observation is away from the mean. It is calculated using the formula:\n",
    "\n",
    "z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "X = the value of the observation (in this case, X = 60)\n",
    "μ = the mean of the dataset (given as 50)\n",
    "σ = the standard deviation of the dataset (given as 10)\n",
    "\n",
    "Now, let's calculate the z-score for X = 60:\n",
    "\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "The z-score of 1 indicates that the value 60 is 1 standard deviation above the mean.\n",
    "\n",
    "Next, we need to find the probability that a randomly selected observation is greater than 60. We can do this by finding the area under the standard normal distribution curve to the right of the z-score of 1. This area represents the probability that a value is greater than 60.\n",
    "\n",
    "Using a standard normal distribution table or a calculator, we can find that the probability corresponding to a z-score of 1 is approximately 0.8413.\n",
    "\n",
    "So, the probability that a randomly selected observation from the dataset is greater than 60 is approximately 0.8413 or 84.13%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40d623",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa2c33",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that describes a random variable where all values within a specific range are equally likely to occur. In other words, in a uniform distribution, the probability of observing any value within the given range is constant and uniform.\n",
    "\n",
    "The probability density function (PDF) of the uniform distribution is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "where:\n",
    "\n",
    "a is the minimum value of the range,\n",
    "b is the maximum value of the range,\n",
    "x is the random variable within the range.\n",
    "The cumulative distribution function (CDF) for the uniform distribution is a linear function and is defined as:\n",
    "\n",
    "F(x) = (x - a) / (b - a) for a ≤ x ≤ b\n",
    "F(x) = 0 for x < a\n",
    "F(x) = 1 for x > b\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "\n",
    "Let's consider an example of a fair six-sided die. When rolling the die, the outcome can be any of the integers from 1 to 6, and each outcome is equally likely.\n",
    "\n",
    "In this case, the uniform distribution represents the probability of each possible outcome:\n",
    "\n",
    "For a fair six-sided die, the range of possible outcomes is from a = 1 (minimum value) to b = 6 (maximum value).\n",
    "\n",
    "The probability of rolling any specific number (1, 2, 3, 4, 5, or 6) is given by:\n",
    "\n",
    "P(X = 1) = 1 / (6 - 1) = 1/5\n",
    "P(X = 2) = 1 / (6 - 1) = 1/5\n",
    "P(X = 3) = 1 / (6 - 1) = 1/5\n",
    "P(X = 4) = 1 / (6 - 1) = 1/5\n",
    "P(X = 5) = 1 / (6 - 1) = 1/5\n",
    "P(X = 6) = 1 / (6 - 1) = 1/5\n",
    "\n",
    "Each probability is equal to 1/5, indicating that each outcome has an equal chance of occurring.\n",
    "\n",
    "Graphically, the probability density function (PDF) of a uniform distribution appears as a flat, constant line between a and b, representing the uniform probabilities across the range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f20897",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261e6bb",
   "metadata": {},
   "source": [
    "A z-score is a statistical measure that tells you how far away a specific point is from the mean in terms of standard deviations. It is calculated by subtracting the mean from the point and then dividing by the standard deviation.\n",
    "\n",
    "The z-score is important because it allows you to compare different sets of data that have different means and standard deviations. For example, if you have two sets of data, one with a mean of 50 and a standard deviation of 10, and the other with a mean of 75 and a standard deviation of 15, you can use the z-score to compare the two sets of data.\n",
    "\n",
    "To do this, you would calculate the z-score for each point in each set of data. The z-score for a point in the first set of data would be calculated by subtracting the mean of the first set of data (50) from the point and then dividing by the standard deviation of the first set of data (10). The z-score for a point in the second set of data would be calculated by subtracting the mean of the second set of data (75) from the point and then dividing by the standard deviation of the second set of data (15).\n",
    "\n",
    "Once you have calculated the z-scores for each point in each set of data, you can compare the z-scores to see which points are further away from the mean in each set of data. The points with the highest z-scores are the points that are furthest away from the mean in their respective sets of data.\n",
    "\n",
    "The z-score is a powerful tool that can be used to compare different sets of data. It is a versatile tool that can be used in a variety of statistical applications.\n",
    "\n",
    "Here are some of the importance of z-scores:\n",
    "\n",
    "Z-scores can be used to compare different sets of data that have different means and standard deviations.\n",
    "Z-scores can be used to identify outliers in a data set.\n",
    "Z-scores can be used to calculate the probability of a particular value occurring in a data set.\n",
    "Z-scores can be used to standardize data sets, which makes them easier to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b8836",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826ec14",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of sample means or sample sums of a large number of independent and identically distributed random variables. It states that, regardless of the shape of the original population distribution, as the sample size increases, the sampling distribution of the sample mean approaches a normal distribution.\n",
    "\n",
    "\n",
    "Sample Means Converge to Normal Distribution: When we take repeated random samples of a fixed size from any population, calculate the means of those samples, and plot the distribution of those sample means, the resulting sampling distribution will tend to be approximately normal.\n",
    "\n",
    "Sample Size Matters: The larger the sample size, the better the approximation to the normal distribution, even if the underlying population is not normally distributed.\n",
    "\n",
    "Independence and Identically Distributed (IID) Samples: The Central Limit Theorem assumes that the random samples are drawn independently and have the same probability distribution. In practice, this condition is typically met in random sampling scenarios.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Real-World Applications: The Central Limit Theorem has immense practical significance in statistics and data analysis. It allows us to make inferences about a population based on sample data even when we have little or no information about the population distribution. This is because the sampling distribution of the sample mean will tend to be normally distributed, providing us with powerful tools for hypothesis testing and constructing confidence intervals.\n",
    "\n",
    "Hypothesis Testing: The Central Limit Theorem is the foundation for many hypothesis tests, such as the z-test and t-test. These tests rely on the normality of the sampling distribution to assess whether sample means differ significantly from hypothesized values or from each other.\n",
    "\n",
    "Confidence Intervals: The CLT is crucial for constructing confidence intervals for population parameters, such as the population mean. These intervals provide a range of values within which the true population parameter is likely to lie with a certain level of confidence.\n",
    "\n",
    "Large Sample Size Approximations: For large sample sizes, the normal distribution is widely applicable in approximating the sampling distribution of sample statistics, such as the mean and proportion. This simplifies calculations and facilitates statistical analyses.\n",
    "\n",
    "Sampling Efficiency: The CLT demonstrates that larger sample sizes lead to more efficient estimates of population parameters. As the sample size increases, the standard error of the sample mean decreases, allowing for more precise estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd7433e",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64098c24",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics, but it relies on certain assumptions for its validity. These assumptions are important to ensure that the CLT holds true in practice. The assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "Random Sampling: The samples should be drawn randomly from the population of interest. Each observation in the sample should be independent of the others, meaning that the value of one observation does not influence the value of another.\n",
    "\n",
    "Independence: The individual observations in each sample should be independent of each other. This assumption ensures that the samples are not affected by any systematic biases or external factors.\n",
    "\n",
    "Identically Distributed: The observations in the samples should be identically distributed. This means that each sample is drawn from the same population and follows the same underlying probability distribution.\n",
    "\n",
    "Finite Variance: The population from which the samples are drawn should have a finite variance. If the population variance is infinite or undefined, the CLT may not hold.\n",
    "\n",
    "Sample Size: For the CLT to work effectively, the sample size should be reasonably large. In practice, a sample size of 30 or greater is often considered sufficient for the CLT to provide a good approximation of the sampling distribution of the sample mean.\n",
    "\n",
    "Population Distribution Shape: The CLT is robust and can work with various population distributions. However, for small sample sizes, the population distribution may need to be approximately symmetric, and for larger sample sizes, the population distribution can be more skewed without significantly affecting the CLT's applicability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
